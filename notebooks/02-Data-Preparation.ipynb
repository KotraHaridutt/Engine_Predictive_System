{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b79dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data with 20631 rows.\n",
      "   unit_number  time_cycle  setting_1  setting_2  setting_3  sensor_1  \\\n",
      "0            1           1    -0.0007    -0.0004      100.0    518.67   \n",
      "1            1           2     0.0019    -0.0003      100.0    518.67   \n",
      "2            1           3    -0.0043     0.0003      100.0    518.67   \n",
      "3            1           4     0.0007     0.0000      100.0    518.67   \n",
      "4            1           5    -0.0019    -0.0002      100.0    518.67   \n",
      "\n",
      "   sensor_2  sensor_3  sensor_4  sensor_5  ...  sensor_12  sensor_13  \\\n",
      "0    641.82   1589.70   1400.60     14.62  ...     521.66    2388.02   \n",
      "1    642.15   1591.82   1403.14     14.62  ...     522.28    2388.07   \n",
      "2    642.35   1587.99   1404.20     14.62  ...     522.42    2388.03   \n",
      "3    642.35   1582.79   1401.87     14.62  ...     522.86    2388.08   \n",
      "4    642.37   1582.85   1406.22     14.62  ...     522.19    2388.04   \n",
      "\n",
      "   sensor_14  sensor_15  sensor_16  sensor_17  sensor_18  sensor_19  \\\n",
      "0    8138.62     8.4195       0.03        392       2388      100.0   \n",
      "1    8131.49     8.4318       0.03        392       2388      100.0   \n",
      "2    8133.23     8.4178       0.03        390       2388      100.0   \n",
      "3    8133.83     8.3682       0.03        392       2388      100.0   \n",
      "4    8133.80     8.4294       0.03        393       2388      100.0   \n",
      "\n",
      "   sensor_20  sensor_21  \n",
      "0      39.06    23.4190  \n",
      "1      39.00    23.4236  \n",
      "2      38.95    23.3442  \n",
      "3      38.88    23.3739  \n",
      "4      38.90    23.4044  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_17742/3206098320.py:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  sep='\\s+',\n"
     ]
    }
   ],
   "source": [
    "column_names = ['unit_number', 'time_cycle', \n",
    "                'setting_1', 'setting_2', 'setting_3',\n",
    "                'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5',\n",
    "                'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10',\n",
    "                'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15',\n",
    "                'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19', 'sensor_20',\n",
    "                'sensor_21']\n",
    "\n",
    "# Define paths\n",
    "train_path = '/workspaces/Engine_Predictive_System/data/train_FD001.txt'\n",
    "\n",
    "# Load the training data\n",
    "df_train = pd.read_csv(train_path, \n",
    "                       sep='\\s+', \n",
    "                       header=None, \n",
    "                       names=column_names)\n",
    "\n",
    "df_train = df_train.dropna(axis='columns', how='all')\n",
    "\n",
    "print(f\"Loaded training data with {df_train.shape[0]} rows.\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sensor Variance ---\n",
      "unit_number    8.542545e+02\n",
      "time_cycle     4.744591e+03\n",
      "setting_1      4.784340e-06\n",
      "setting_2      8.588541e-08\n",
      "setting_3      0.000000e+00\n",
      "sensor_1       0.000000e+00\n",
      "sensor_2       2.500533e-01\n",
      "sensor_3       3.759099e+01\n",
      "sensor_4       8.101089e+01\n",
      "sensor_5       2.840037e-29\n",
      "sensor_6       1.929279e-06\n",
      "sensor_7       7.833883e-01\n",
      "sensor_8       5.038938e-03\n",
      "sensor_9       4.876536e+02\n",
      "sensor_10      0.000000e+00\n",
      "sensor_11      7.133568e-02\n",
      "sensor_12      5.439850e-01\n",
      "sensor_13      5.172330e-03\n",
      "sensor_14      3.639005e+02\n",
      "sensor_15      1.406628e-03\n",
      "sensor_16      1.203765e-35\n",
      "sensor_17      2.398667e+00\n",
      "sensor_18      0.000000e+00\n",
      "sensor_19      0.000000e+00\n",
      "sensor_20      3.266927e-02\n",
      "sensor_21      1.171825e-02\n",
      "dtype: float64\n",
      "\n",
      "Dropping 9 useless/constant columns:\n",
      "['sensor_18', 'setting_3', 'sensor_1', 'sensor_5', 'setting_2', 'sensor_10', 'sensor_16', 'setting_1', 'sensor_19']\n",
      "\n",
      "--- Cleaned Data (First 5 Rows) ---\n",
      "   unit_number  time_cycle  sensor_2  sensor_3  sensor_4  sensor_6  sensor_7  \\\n",
      "0            1           1    641.82   1589.70   1400.60     21.61    554.36   \n",
      "1            1           2    642.15   1591.82   1403.14     21.61    553.75   \n",
      "2            1           3    642.35   1587.99   1404.20     21.61    554.26   \n",
      "3            1           4    642.35   1582.79   1401.87     21.61    554.45   \n",
      "4            1           5    642.37   1582.85   1406.22     21.61    554.00   \n",
      "\n",
      "   sensor_8  sensor_9  sensor_11  sensor_12  sensor_13  sensor_14  sensor_15  \\\n",
      "0   2388.06   9046.19      47.47     521.66    2388.02    8138.62     8.4195   \n",
      "1   2388.04   9044.07      47.49     522.28    2388.07    8131.49     8.4318   \n",
      "2   2388.08   9052.94      47.27     522.42    2388.03    8133.23     8.4178   \n",
      "3   2388.11   9049.48      47.13     522.86    2388.08    8133.83     8.3682   \n",
      "4   2388.06   9055.15      47.28     522.19    2388.04    8133.80     8.4294   \n",
      "\n",
      "   sensor_17  sensor_20  sensor_21  \n",
      "0        392      39.06    23.4190  \n",
      "1        392      39.00    23.4236  \n",
      "2        390      38.95    23.3442  \n",
      "3        392      38.88    23.3739  \n",
      "4        393      38.90    23.4044  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's check for any sensors that have zero variance (i.e., they never change)\n",
    "# These sensors provide no information and should be dropped.\n",
    "\n",
    "sensor_variance = df_train.var()\n",
    "print(\"--- Sensor Variance ---\")\n",
    "print(sensor_variance)\n",
    "\n",
    "# Identify columns with zero variance (or very close to it)\n",
    "# These are often 'setting_3', 'sensor_1', 'sensor_5', 'sensor_10', 'sensor_16', 'sensor_18', 'sensor_19'\n",
    "# Let's find them automatically\n",
    "cols_to_drop = sensor_variance[sensor_variance < 1e-10].index.tolist()\n",
    "\n",
    "# Also, 'setting_3' is often constant and can be dropped if it's in there\n",
    "if 'setting_3' not in cols_to_drop:\n",
    "     cols_to_drop.append('setting_3')\n",
    "\n",
    "# We also drop the 'settings' as they aren't sensors\n",
    "cols_to_drop.extend(['setting_1', 'setting_2'])\n",
    "        \n",
    "# Let's make sure we don't accidentally drop essential columns\n",
    "cols_to_drop = [col for col in cols_to_drop if col in df_train.columns and col not in ['unit_number', 'time_cycle']]\n",
    "        \n",
    "# Remove duplicates\n",
    "cols_to_drop = list(set(cols_to_drop)) \n",
    "\n",
    "print(f\"\\nDropping {len(cols_to_drop)} useless/constant columns:\")\n",
    "print(cols_to_drop)\n",
    "\n",
    "# Drop the columns\n",
    "df_train_cleaned = df_train.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"\\n--- Cleaned Data (First 5 Rows) ---\")\n",
    "print(df_train_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data with RUL Engineered (First 5 Rows) ---\n",
      "   unit_number  time_cycle  sensor_2  sensor_3  sensor_4  sensor_6  sensor_7  \\\n",
      "0            1           1    641.82   1589.70   1400.60     21.61    554.36   \n",
      "1            1           2    642.15   1591.82   1403.14     21.61    553.75   \n",
      "2            1           3    642.35   1587.99   1404.20     21.61    554.26   \n",
      "3            1           4    642.35   1582.79   1401.87     21.61    554.45   \n",
      "4            1           5    642.37   1582.85   1406.22     21.61    554.00   \n",
      "\n",
      "   sensor_8  sensor_9  sensor_11  sensor_12  sensor_13  sensor_14  sensor_15  \\\n",
      "0   2388.06   9046.19      47.47     521.66    2388.02    8138.62     8.4195   \n",
      "1   2388.04   9044.07      47.49     522.28    2388.07    8131.49     8.4318   \n",
      "2   2388.08   9052.94      47.27     522.42    2388.03    8133.23     8.4178   \n",
      "3   2388.11   9049.48      47.13     522.86    2388.08    8133.83     8.3682   \n",
      "4   2388.06   9055.15      47.28     522.19    2388.04    8133.80     8.4294   \n",
      "\n",
      "   sensor_17  sensor_20  sensor_21  RUL  \n",
      "0        392      39.06    23.4190  191  \n",
      "1        392      39.00    23.4236  190  \n",
      "2        390      38.95    23.3442  189  \n",
      "3        392      38.88    23.3739  188  \n",
      "4        393      38.90    23.4044  187  \n",
      "\n",
      "--- Spot Check: Engine 1 (End of Life) ---\n",
      "     unit_number  time_cycle  sensor_2  sensor_3  sensor_4  sensor_6  \\\n",
      "187            1         188    643.75   1602.38   1422.78     21.61   \n",
      "188            1         189    644.18   1596.17   1428.01     21.61   \n",
      "189            1         190    643.64   1599.22   1425.95     21.61   \n",
      "190            1         191    643.34   1602.36   1425.77     21.61   \n",
      "191            1         192    643.54   1601.41   1427.20     21.61   \n",
      "\n",
      "     sensor_7  sensor_8  sensor_9  sensor_11  sensor_12  sensor_13  sensor_14  \\\n",
      "187    551.94   2388.31   9037.91      48.00     519.79    2388.23    8117.69   \n",
      "188    550.70   2388.27   9044.55      48.08     519.58    2388.33    8117.51   \n",
      "189    551.29   2388.29   9040.58      48.33     520.04    2388.35    8112.58   \n",
      "190    550.92   2388.28   9042.76      48.15     519.57    2388.30    8114.61   \n",
      "191    551.25   2388.32   9033.22      48.25     520.08    2388.32    8110.93   \n",
      "\n",
      "     sensor_15  sensor_17  sensor_20  sensor_21  RUL  \n",
      "187     8.5207        396      38.51    22.9588    4  \n",
      "188     8.5183        395      38.48    23.1127    3  \n",
      "189     8.5223        398      38.49    23.0675    2  \n",
      "190     8.5174        394      38.45    23.1295    1  \n",
      "191     8.5113        396      38.48    22.9649    0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Our data shows an engine's life *up to failure*.\n",
    "# We need to calculate the RUL for every single row.\n",
    "# RUL = (Total cycles for that engine) - (Current cycle for that row)\n",
    "\n",
    "# 1. Find the maximum (failure) cycle for each engine\n",
    "df_max_cycles = df_train_cleaned.groupby('unit_number')['time_cycle'].max().reset_index()\n",
    "df_max_cycles.columns = ['unit_number', 'max_cycle']\n",
    "\n",
    "# 2. Merge this max_cycle value back onto the main dataframe\n",
    "df_train_rul = df_train_cleaned.merge(df_max_cycles, on='unit_number', how='left')\n",
    "\n",
    "# 3. Create the 'RUL' column\n",
    "df_train_rul['RUL'] = df_train_rul['max_cycle'] - df_train_rul['time_cycle']\n",
    "\n",
    "# 4. Drop the temporary 'max_cycle' column\n",
    "df_train_rul = df_train_rul.drop(columns=['max_cycle'])\n",
    "\n",
    "print(\"\\n--- Data with RUL Engineered (First 5 Rows) ---\")\n",
    "print(df_train_rul.head())\n",
    "\n",
    "# Spot check: Look at the last few rows for engine 1. The RUL should count down to 0.\n",
    "print(\"\\n--- Spot Check: Engine 1 (End of Life) ---\")\n",
    "print(df_train_rul[df_train_rul['unit_number'] == 1].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connecting to SQL database at /workspaces/Engine_Predictive_System/data/turbofan.db...\n",
      "Successfully wrote 20631 rows to table 'train_data_FD001'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now we save this fully-prepared DataFrame into a clean SQL database.\n",
    "# This database will be the \"single source of truth\" for the rest of our project.\n",
    "\n",
    "# Define the database path. We'll store it in the 'data' folder.\n",
    "db_path = '/workspaces/Engine_Predictive_System/data/turbofan.db'\n",
    "table_name = 'train_data_FD001'\n",
    "\n",
    "# Create a connection\n",
    "conn = sqlite3.connect(db_path)\n",
    "print(f\"\\nConnecting to SQL database at {db_path}...\")\n",
    "\n",
    "# Use pandas .to_sql() to write the DataFrame to the SQL table\n",
    "# if_exists='replace' means it will overwrite the table if it already exists.\n",
    "df_train_rul.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Successfully wrote {df_train_rul.shape[0]} rows to table '{table_name}'.\")\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying SQL Database ---\n",
      "Test query successful! Data from DB:\n",
      "   unit_number  time_cycle  sensor_2  sensor_3  sensor_4  sensor_6  sensor_7  \\\n",
      "0            1           1    641.82   1589.70   1400.60     21.61    554.36   \n",
      "1            1           2    642.15   1591.82   1403.14     21.61    553.75   \n",
      "2            1           3    642.35   1587.99   1404.20     21.61    554.26   \n",
      "3            1           4    642.35   1582.79   1401.87     21.61    554.45   \n",
      "\n",
      "   sensor_8  sensor_9  sensor_11  sensor_12  sensor_13  sensor_14  sensor_15  \\\n",
      "0   2388.06   9046.19      47.47     521.66    2388.02    8138.62     8.4195   \n",
      "1   2388.04   9044.07      47.49     522.28    2388.07    8131.49     8.4318   \n",
      "2   2388.08   9052.94      47.27     522.42    2388.03    8133.23     8.4178   \n",
      "3   2388.11   9049.48      47.13     522.86    2388.08    8133.83     8.3682   \n",
      "\n",
      "   sensor_17  sensor_20  sensor_21  RUL  \n",
      "0        392      39.06    23.4190  191  \n",
      "1        392      39.00    23.4236  190  \n",
      "2        390      38.95    23.3442  189  \n",
      "3        392      38.88    23.3739  188  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's read the data *back* from the SQL DB to prove it worked.\n",
    "\n",
    "print(\"\\n--- Verifying SQL Database ---\")\n",
    "try:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Run a test query\n",
    "    query = f\"SELECT * FROM {table_name} WHERE unit_number = 1 AND time_cycle < 5\"\n",
    "    df_from_db = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(\"Test query successful! Data from DB:\")\n",
    "    print(df_from_db)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during verification: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
